{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45b275ba",
   "metadata": {},
   "source": [
    "## DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0372bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43ac632f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('datasets/reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffb3c81a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47e7cc00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.<br /><br />It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.<br /><br />I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6d8678",
   "metadata": {},
   "source": [
    "### Tasks for data cleaning\n",
    "- sample is reduced to 10000\n",
    "- remove html tags\n",
    "- remove special characters\n",
    "- convert to lower case\n",
    "- remove stopwords\n",
    "- stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95e7f8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.sample(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f110dcc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6aaf3d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10000 entries, 49060 to 30892\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   review     10000 non-null  object\n",
      " 1   sentiment  10000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 234.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1204cc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment'].replace({'positive':1,'negative':0}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b2444f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49060</th>\n",
       "      <td>Unentertaining, uninvolving hybrid of \"Cruel I...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>The Last Hard Men finds James Coburn an outlaw...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43507</th>\n",
       "      <td>It's hard to know what was going through Per K...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26702</th>\n",
       "      <td>I have heard about this novel a long time ago,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20963</th>\n",
       "      <td>Enjoyed 'Den brysomme mannen' http://ow.ly/PTT...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  sentiment\n",
       "49060  Unentertaining, uninvolving hybrid of \"Cruel I...          0\n",
       "76     The Last Hard Men finds James Coburn an outlaw...          1\n",
       "43507  It's hard to know what was going through Per K...          0\n",
       "26702  I have heard about this novel a long time ago,...          0\n",
       "20963  Enjoyed 'Den brysomme mannen' http://ow.ly/PTT...          1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "45453acb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'It\\'s hard to know what was going through Per Kristensen and Morten Lindberg\\'s heads when they wrote \"Gayniggers from Outer Space\" - the movie is billed as a comedy, yet there are no real jokes beside the crude character names (Capt. B. Dick, Sgt. Shaved Balls). The rest of the movie is a (presumably) unintentionally funny affair with ridiculously unsynchronised voice-overs (with the \\'actors\\' basically reading their lines with no hint of feeling), \\'futuristic\\' computer displays filled with spelling mistakes, and a plot that makes almost no sense.Even though 65% of viewers have given this movie a perfect 10 out of 10, this is the complete opposite of what a good film is. It may be ENTERTAINING to watch with some friends, but this film only deserves about a \\'2\\' out of ten...slightly higher than the lower possible rating only because of the sheer fact that the writers somehow managed to get some black guys to star in this movie.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "clean=re.compile('<.*?>')\n",
    "re.sub(clean, '', df.iloc[2].review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4246ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to clean html tags\n",
    "def clean_html(text):\n",
    "    clean=re.compile('<.*?>')\n",
    "    return re.sub(clean, '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "524b0acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review']=df['review'].apply(clean_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "221ec99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to convert to lower case\n",
    "def convert_lower(text):\n",
    "    return text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "51c1e821",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review']=df['review'].apply(convert_lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bacf3083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to remove special characters\n",
    "def remove_special(text):\n",
    "    x= ''\n",
    "    for i in text:\n",
    "        if i.isalnum():\n",
    "            x = x+i\n",
    "        else:\n",
    "            x = x+' '\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "996b17cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review']=df['review'].apply(remove_special)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6c05eb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fcaf267c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "10e939ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for removing stopwords\n",
    "def remove_stopwords(text):\n",
    "    x=[]\n",
    "    for i in text.split():\n",
    "        if i not in stopwords.words('english'):\n",
    "            x.append(i)\n",
    "    y=x[:]\n",
    "    x.clear()\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "74f7f0b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49060</th>\n",
       "      <td>[unentertaining, uninvolving, hybrid, cruel, i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>[last, hard, men, finds, james, coburn, outlaw...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43507</th>\n",
       "      <td>[hard, know, going, per, kristensen, morten, l...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26702</th>\n",
       "      <td>[heard, novel, long, time, ago, many, friends,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20963</th>\n",
       "      <td>[enjoyed, den, brysomme, mannen, http, ow, ly,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3402</th>\n",
       "      <td>[well, made, film, set, early, 60s, communist,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8375</th>\n",
       "      <td>[really, enjoyed, film, tremendous, interest, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10498</th>\n",
       "      <td>[like, singin, rain, cover, girl, trio, two, g...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4880</th>\n",
       "      <td>[friend, mine, loves, tacky, horror, films, of...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30892</th>\n",
       "      <td>[wes, craven, laugh, expense, red, eye, plot, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  sentiment\n",
       "49060  [unentertaining, uninvolving, hybrid, cruel, i...          0\n",
       "76     [last, hard, men, finds, james, coburn, outlaw...          1\n",
       "43507  [hard, know, going, per, kristensen, morten, l...          0\n",
       "26702  [heard, novel, long, time, ago, many, friends,...          0\n",
       "20963  [enjoyed, den, brysomme, mannen, http, ow, ly,...          1\n",
       "...                                                  ...        ...\n",
       "3402   [well, made, film, set, early, 60s, communist,...          1\n",
       "8375   [really, enjoyed, film, tremendous, interest, ...          1\n",
       "10498  [like, singin, rain, cover, girl, trio, two, g...          0\n",
       "4880   [friend, mine, loves, tacky, horror, films, of...          0\n",
       "30892  [wes, craven, laugh, expense, red, eye, plot, ...          0\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review']=df['review'].apply(remove_stopwords)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5c99e95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "ps=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8345ef3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for stemming\n",
    "y=[]\n",
    "def stem_words(text):\n",
    "    for i in text:\n",
    "        y.append(ps.stem(i))\n",
    "    z=y[:]\n",
    "    y.clear()\n",
    "    \n",
    "    return z\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "616fbfa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49060</th>\n",
       "      <td>[unentertain, uninvolv, hybrid, cruel, intent,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>[last, hard, men, find, jame, coburn, outlaw, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43507</th>\n",
       "      <td>[hard, know, go, per, kristensen, morten, lind...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26702</th>\n",
       "      <td>[heard, novel, long, time, ago, mani, friend, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20963</th>\n",
       "      <td>[enjoy, den, brysomm, mannen, http, ow, ly, pt...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3402</th>\n",
       "      <td>[well, made, film, set, earli, 60, communist, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8375</th>\n",
       "      <td>[realli, enjoy, film, tremend, interest, ameri...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10498</th>\n",
       "      <td>[like, singin, rain, cover, girl, trio, two, g...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4880</th>\n",
       "      <td>[friend, mine, love, tacki, horror, film, ofte...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30892</th>\n",
       "      <td>[we, craven, laugh, expens, red, eye, plot, pr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  sentiment\n",
       "49060  [unentertain, uninvolv, hybrid, cruel, intent,...          0\n",
       "76     [last, hard, men, find, jame, coburn, outlaw, ...          1\n",
       "43507  [hard, know, go, per, kristensen, morten, lind...          0\n",
       "26702  [heard, novel, long, time, ago, mani, friend, ...          0\n",
       "20963  [enjoy, den, brysomm, mannen, http, ow, ly, pt...          1\n",
       "...                                                  ...        ...\n",
       "3402   [well, made, film, set, earli, 60, communist, ...          1\n",
       "8375   [realli, enjoy, film, tremend, interest, ameri...          1\n",
       "10498  [like, singin, rain, cover, girl, trio, two, g...          0\n",
       "4880   [friend, mine, love, tacki, horror, film, ofte...          0\n",
       "30892  [we, craven, laugh, expens, red, eye, plot, pr...          0\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review']=df['review'].apply(stem_words)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "718e20a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join\n",
    "def join(list_input):\n",
    "    return \" \".join(list_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "70bebf9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49060</th>\n",
       "      <td>unentertain uninvolv hybrid cruel intent wild ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>last hard men find jame coburn outlaw long sen...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43507</th>\n",
       "      <td>hard know go per kristensen morten lindberg he...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26702</th>\n",
       "      <td>heard novel long time ago mani friend recommen...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20963</th>\n",
       "      <td>enjoy den brysomm mannen http ow ly pttp wife ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3402</th>\n",
       "      <td>well made film set earli 60 communist yugoslav...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8375</th>\n",
       "      <td>realli enjoy film tremend interest american hi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10498</th>\n",
       "      <td>like singin rain cover girl trio two guy girl ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4880</th>\n",
       "      <td>friend mine love tacki horror film often get s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30892</th>\n",
       "      <td>we craven laugh expens red eye plot preposter ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  sentiment\n",
       "49060  unentertain uninvolv hybrid cruel intent wild ...          0\n",
       "76     last hard men find jame coburn outlaw long sen...          1\n",
       "43507  hard know go per kristensen morten lindberg he...          0\n",
       "26702  heard novel long time ago mani friend recommen...          0\n",
       "20963  enjoy den brysomm mannen http ow ly pttp wife ...          1\n",
       "...                                                  ...        ...\n",
       "3402   well made film set earli 60 communist yugoslav...          1\n",
       "8375   realli enjoy film tremend interest american hi...          1\n",
       "10498  like singin rain cover girl trio two guy girl ...          0\n",
       "4880   friend mine love tacki horror film often get s...          0\n",
       "30892  we craven laugh expens red eye plot preposter ...          0\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review']=df['review'].apply(join)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee205a8b",
   "metadata": {},
   "source": [
    "### TFIDF vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc7ab370",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-bd2021062ff8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_extraction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtfidf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtfidf_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'review'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mtfidf_matrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf.fit_transform(df['review']).toarray()\n",
    "tfidf_matrix.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7db22e8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7024ced0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matrix[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6219cd09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35522638751670155"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matrix[0].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e6ffbf2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=df.iloc[:,-1].values\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5911d759",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tfidf_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-9a456c78c8b4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtfidf_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'tfidf_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_matrix, y, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff079a7e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-6c7e839255ef>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "X_train.shape,X_test.shape,y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a9384514",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB,MultinomialNB,BernoulliNB\n",
    "cl1 = GaussianNB()\n",
    "cl2 = MultinomialNB()\n",
    "cl3 = BernoulliNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "cb0d39ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB()"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl1.fit(X_train,y_train)\n",
    "cl2.fit(X_train,y_train)\n",
    "cl3.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "83687aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB  0.617\n",
      "MultinomialNB  0.845\n",
      "BernoulliNB  0.83\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(\"GaussianNB \",accuracy_score(y_test,cl1.predict(X_test)))\n",
    "print(\"MultinomialNB \",accuracy_score(y_test,cl2.predict(X_test)))\n",
    "print(\"BernoulliNB \",accuracy_score(y_test,cl3.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db3df94",
   "metadata": {},
   "source": [
    "### Bag of words count vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2d867c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv=CountVectorizer() # change the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0dced018",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=cv.fit_transform(df['review']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7704bfd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 36198)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7d764b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=df.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "60d22be6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "03b86703",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "34beac9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB,MultinomialNB,BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "0a80571a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = GaussianNB()\n",
    "clf2 = MultinomialNB()\n",
    "clf3 = BernoulliNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d5742df0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB()"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1.fit(X_train,y_train)\n",
    "clf2.fit(X_train,y_train)\n",
    "clf3.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "047474cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = clf1.predict(X_test)\n",
    "y_pred2 = clf2.predict(X_test)\n",
    "y_pred3 = clf3.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7758a15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "2ff58881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB  0.628\n",
      "MultinomialNB  0.846\n",
      "BernoulliNB  0.853\n"
     ]
    }
   ],
   "source": [
    "print(\"GaussianNB \",accuracy_score(y_test,y_pred1))\n",
    "print(\"MultinomialNB \",accuracy_score(y_test,y_pred2))\n",
    "print(\"BernoulliNB \",accuracy_score(y_test,y_pred3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13eeba3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
